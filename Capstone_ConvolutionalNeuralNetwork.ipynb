{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "29b9bd1d-766f-4422-ad96-de0accc1ce58"
    }
   },
   "source": [
    "# Capstone - CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "138d1a78-02e2-4bd6-a20e-07b83f303563"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function # Use a function definition from future version (say 3.x from 2.7 interpreter)\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import cntk as C\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the block below, we check if we are running this notebook in the CNTK internal test machines by looking for environment variables defined there. We then select the right target device (GPU vs CPU) to test this notebook. In other cases, we use CNTK's default policy to use the best available device (GPU, if available, else CPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Specified GPU device id (0) is invalid.\n\n[CALL STACK]\n    > CNTK::Parameter::  SetValue\n    - CNTK::DeviceDescriptor::  GPUDevice\n    - PyInit__cntk_py\n    - PyCFunction_FastCallDict\n    - PyObject_CallFunctionObjArgs\n    - PyEval_EvalFrameDefault\n    - Py_CheckFunctionResult\n    - PyList_Size\n    - PyEval_EvalFrameDefault\n    - Py_CheckFunctionResult\n    - PyObject_CallFunctionObjArgs\n    - PyEval_EvalFrameDefault\n    - Py_CheckFunctionResult\n    - PyEval_GetGlobals (x2)\n    - PyCFunction_FastCallDict\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b0667d222bf6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtry_set_default_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\cntk\\internal\\swig_helper.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[0mmap_if_possible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\cntk\\device.py\u001b[0m in \u001b[0;36mgpu\u001b[1;34m(device_id)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[1;32mclass\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mcntk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDeviceDescriptor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mGPU\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0mdescriptor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     '''\n\u001b[1;32m---> 96\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcntk_py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDeviceDescriptor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpu_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Specified GPU device id (0) is invalid.\n\n[CALL STACK]\n    > CNTK::Parameter::  SetValue\n    - CNTK::DeviceDescriptor::  GPUDevice\n    - PyInit__cntk_py\n    - PyCFunction_FastCallDict\n    - PyObject_CallFunctionObjArgs\n    - PyEval_EvalFrameDefault\n    - Py_CheckFunctionResult\n    - PyList_Size\n    - PyEval_EvalFrameDefault\n    - Py_CheckFunctionResult\n    - PyObject_CallFunctionObjArgs\n    - PyEval_EvalFrameDefault\n    - Py_CheckFunctionResult\n    - PyEval_GetGlobals (x2)\n    - PyCFunction_FastCallDict\n\n"
     ]
    }
   ],
   "source": [
    "# Select the right target device when this notebook is being tested:\n",
    "if 'TEST_DEVICE' in os.environ:\n",
    "    if os.environ['TEST_DEVICE'] == 'cpu':\n",
    "        C.device.try_set_default_device(C.device.cpu())\n",
    "    else:\n",
    "        C.device.try_set_default_device(C.device.gpu(0))\n",
    "        \n",
    "print(C.device.gpu(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "this notebook is designed to work with 2.0. Current Version: 2.5.1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-487c1293ba85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Test for CNTK version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"2.0\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"this notebook is designed to work with 2.0. Current Version: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mException\u001b[0m: this notebook is designed to work with 2.0. Current Version: 2.5.1"
     ]
    }
   ],
   "source": [
    "# Test for CNTK version\n",
    "if not C.__version__ == \"2.0\":\n",
    "    raise Exception(\"this notebook is designed to work with 2.0. Current Version: \" + C.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ensure we always get the same amount of randomness\n",
    "np.random.seed(0)\n",
    "C.cntk_py.set_fixed_random_seed(1)\n",
    "C.cntk_py.force_deterministic_algorithms()\n",
    "\n",
    "# Define the data dimensions\n",
    "input_dim_model = (1, 64, 64)    # images are 64 x 64 with 1 channel of color (gray)\n",
    "input_dim = 64*64                # used by readers to treat input data as a vector\n",
    "num_output_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read a CTF formatted text (as mentioned above) using the CTF deserializer from a file\n",
    "def create_reader(path, is_training, input_dim, num_label_classes):\n",
    "    \n",
    "    ctf = C.io.CTFDeserializer(path, C.io.StreamDefs(\n",
    "          labels=C.io.StreamDef(field='labels', shape=num_label_classes, is_sparse=False),\n",
    "          features=C.io.StreamDef(field='features', shape=input_dim, is_sparse=False)))\n",
    "                          \n",
    "    return C.io.MinibatchSource(ctf,\n",
    "        randomize = is_training, max_sweeps = C.io.INFINITELY_REPEAT if is_training else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory is Capstone\n"
     ]
    }
   ],
   "source": [
    "# Ensure the training and test data is available\n",
    "# We search in two locations in the toolkit for the cached MNIST data set.\n",
    "\n",
    "data_found=False # A flag to indicate if train/test data found in local cache\n",
    "for data_dir in [os.path.join(\"..\", \"Examples\", \"Image\", \"DataSets\", \"MNIST\"),\n",
    "                 os.path.join(\"Capstone\")]:\n",
    "    \n",
    "    train_file=os.path.join(data_dir, \"Train_data.txt\")\n",
    "    test_file=os.path.join(data_dir, \"Validation_data.txt\")\n",
    "    \n",
    "    if os.path.isfile(train_file) and os.path.isfile(test_file):\n",
    "        data_found=True\n",
    "        break\n",
    "        \n",
    "if not data_found:\n",
    "    raise ValueError(\"Please generate the data by completing Capstone_DataLoader\")\n",
    "    \n",
    "print(\"Data directory is {0}\".format(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = C.input_variable(input_dim_model)\n",
    "y = C.input_variable(num_output_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to build model\n",
    "\n",
    "def create_model(features):\n",
    "    with C.layers.default_options(init=C.glorot_uniform(), activation=C.leaky_relu):\n",
    "            h = features\n",
    "            h = C.layers.Convolution2D(filter_shape=(3,3), \n",
    "                                       num_filters=25, #8\n",
    "                                       strides=(2,2), \n",
    "                                       pad=True, name='first_conv')(h)\n",
    "            h = C.layers.Convolution2D(filter_shape=(3,3), \n",
    "                                       num_filters=50, #16\n",
    "                                       strides=(2,2), \n",
    "                                       pad=True, name='second_conv')(h)\n",
    "            h = C.layers.Convolution2D(filter_shape=(3,3), \n",
    "                                       num_filters=100, #16\n",
    "                                       strides=(2,2), \n",
    "                                       pad=True, name='third_conv')(h)\n",
    "            r = C.layers.Dense(num_output_classes, activation=None, name='classify')(h)\n",
    "            return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Shape of the first convolution layer: (25, 32, 32)\n",
      "Output Shape of the second convolution layer: (50, 16, 16)\n",
      "Output Shape of the third convolution layer: (100, 8, 8)\n",
      "Bias value of the last dense layer: [0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "z = create_model(x)\n",
    "\n",
    "# Print the output shapes / parameters of different components\n",
    "print(\"Output Shape of the first convolution layer:\", z.first_conv.shape)\n",
    "print(\"Output Shape of the second convolution layer:\", z.second_conv.shape)\n",
    "print(\"Output Shape of the third convolution layer:\", z.third_conv.shape)\n",
    "print(\"Bias value of the last dense layer:\", z.classify.b.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 82254 parameters in 8 parameter tensors.\n"
     ]
    }
   ],
   "source": [
    "# Number of parameters in the network\n",
    "C.logging.log_number_of_parameters(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We minimize the cross-entropy between the label and predicted probability by the network. Since we are going to build more than one model, we will create a few helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_criterion_function(model, labels):\n",
    "    loss = C.cross_entropy_with_softmax(model, labels)\n",
    "    errs = C.classification_error(model, labels)\n",
    "    return loss, errs # (model, labels) -> (loss, error metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will need a helper function to perform the model training. First let us create additional helper functions that will be needed to visualize different functions associated with training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a utility function to compute the moving average sum.\n",
    "# A more efficient implementation is possible with np.cumsum() function\n",
    "def moving_average(a, w=5):\n",
    "    if len(a) < w:\n",
    "        return a[:]    # Need to send a copy of the array\n",
    "    return [val if idx < w else sum(a[(idx-w):idx])/w for idx, val in enumerate(a)]\n",
    "\n",
    "\n",
    "# Defines a utility that prints the training progress\n",
    "def print_training_progress(trainer, mb, frequency, verbose=1):\n",
    "    training_loss = \"NA\"\n",
    "    eval_error = \"NA\"\n",
    "\n",
    "    if mb%frequency == 0:\n",
    "        training_loss = trainer.previous_minibatch_loss_average\n",
    "        eval_error = trainer.previous_minibatch_evaluation_average\n",
    "        if verbose: \n",
    "            print (\"Minibatch: {0}, Loss: {1:.4f}, Error: {2:.2f}%\".format(mb, training_loss, eval_error*100))\n",
    "        \n",
    "    return mb, training_loss, eval_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure training\n",
    "\n",
    "Previously we have described the concepts of `loss` function, the optimizers or [learners](https://cntk.ai/pythondocs/cntk.learners.html) and the associated machinery needed to train a model. Please refer to earlier labs for gaining familiarility with these concepts. Here we combine model training and testing in a helper function below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test(train_reader, test_reader, model_func, num_sweeps_to_train_with=20):\n",
    "    \n",
    "    # Instantiate the model function; x is the input (feature) variable \n",
    "    # We will scale the input image pixels within 0-1 range by dividing all input value by 255.\n",
    "    model = model_func(x/255)\n",
    "    \n",
    "    # Instantiate the loss and error function\n",
    "    loss, label_error = create_criterion_function(model, y)\n",
    "    \n",
    "    # Instantiate the trainer object to drive the model training\n",
    "    learning_rate = 0.005\n",
    "    lr_schedule = C.learning_rate_schedule(learning_rate, C.UnitType.minibatch)\n",
    "    learner = C.sgd(z.parameters, lr_schedule)\n",
    "    trainer = C.Trainer(z, (loss, label_error), [learner])\n",
    "    \n",
    "    # Initialize the parameters for the trainer\n",
    "    minibatch_size = 128\n",
    "    num_samples_per_sweep = 20000\n",
    "    num_minibatches_to_train = (num_samples_per_sweep * num_sweeps_to_train_with) / minibatch_size\n",
    "    \n",
    "    # Map the data streams to the input and labels.\n",
    "    input_map={\n",
    "        y  : train_reader.streams.labels,\n",
    "        x  : train_reader.streams.features\n",
    "    } \n",
    "    \n",
    "    # Uncomment below for more detailed logging\n",
    "    training_progress_output_freq = 100\n",
    "     \n",
    "    # Start a timer\n",
    "    start = time.time()\n",
    "\n",
    "    for i in range(0, int(num_minibatches_to_train)):\n",
    "        # Read a mini batch from the training data file\n",
    "        data=train_reader.next_minibatch(minibatch_size, input_map=input_map) \n",
    "        trainer.train_minibatch(data)\n",
    "        print_training_progress(trainer, i, training_progress_output_freq, verbose=1)\n",
    "     \n",
    "    # Print training time\n",
    "    print(\"Training took {:.1f} sec\".format(time.time() - start))\n",
    "    \n",
    "    # Test the model\n",
    "    test_input_map = {\n",
    "        y  : test_reader.streams.labels,\n",
    "        x  : test_reader.streams.features\n",
    "    }\n",
    "\n",
    "    # Test data for trained model\n",
    "    test_minibatch_size = 512\n",
    "    num_samples = 20000\n",
    "    num_minibatches_to_test = num_samples // test_minibatch_size\n",
    "\n",
    "    test_result = 0.0   \n",
    "\n",
    "    for i in range(num_minibatches_to_test):\n",
    "    \n",
    "        # We are loading test data in batches specified by test_minibatch_size\n",
    "        # Each data point in the minibatch is a MNIST digit image of 784 dimensions \n",
    "        # with one pixel per dimension that we will encode / decode with the \n",
    "        # trained model.\n",
    "        data = test_reader.next_minibatch(test_minibatch_size, input_map=test_input_map)\n",
    "        eval_error = trainer.test_minibatch(data)\n",
    "        test_result = test_result + eval_error\n",
    "\n",
    "    # Average of evaluation errors of all test minibatches\n",
    "    print(\"Average test error: {0:.2f}%\".format(test_result*100 / num_minibatches_to_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='#Run the trainer'></a>\n",
    "### Run the trainer and test model\n",
    "\n",
    "We are now ready to train our convolutional neural net. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch: 0, Loss: 1.3902, Error: 79.69%\n",
      "Minibatch: 500, Loss: 0.8459, Error: 23.44%\n",
      "Minibatch: 1000, Loss: 0.3876, Error: 9.38%\n",
      "Minibatch: 1500, Loss: 0.2961, Error: 9.38%\n",
      "Minibatch: 2000, Loss: 0.3593, Error: 17.19%\n",
      "Minibatch: 2500, Loss: 0.3185, Error: 10.94%\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<built-in function MinibatchSource_get_next_minibatch> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\cntk\\cntk_py.py\u001b[0m in \u001b[0;36m__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2438\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2439\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_cntk_py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamInformation___hash__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in method 'StreamInformation___hash__', argument 1 of type 'CNTK::StreamInformation *'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-0055cec51ad8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtrain_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreader_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdo_train_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-48-0055cec51ad8>\u001b[0m in \u001b[0;36mdo_train_test\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mreader_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_output_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mreader_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_output_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtrain_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreader_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdo_train_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-42-99e7c549daf3>\u001b[0m in \u001b[0;36mtrain_test\u001b[1;34m(train_reader, test_reader, model_func, num_sweeps_to_train_with)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_minibatches_to_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m# Read a mini batch from the training data file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_minibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminibatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_minibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mprint_training_progress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_progress_output_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\cntk\\internal\\swig_helper.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[0mmap_if_possible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\cntk\\io\\__init__.py\u001b[0m in \u001b[0;36mnext_minibatch\u001b[1;34m(self, minibatch_size_in_samples, input_map, device, num_data_partitions, partition_index)\u001b[0m\n\u001b[0;32m    290\u001b[0m                                             \u001b[0mminibatch_size_in_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m                                             \u001b[0mnum_data_partitions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m                                             partition_index, device)\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\cntk\\cntk_py.py\u001b[0m in \u001b[0;36mget_next_minibatch\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   2608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2609\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_minibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2610\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_cntk_py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMinibatchSource_get_next_minibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2611\u001b[0m \u001b[0mMinibatchSource_swigregister\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_cntk_py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMinibatchSource_swigregister\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2612\u001b[0m \u001b[0mMinibatchSource_swigregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMinibatchSource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: <built-in function MinibatchSource_get_next_minibatch> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "def do_train_test():\n",
    "    global z\n",
    "    z = create_model(x)\n",
    "    reader_train = create_reader(train_file, True, input_dim, num_output_classes)\n",
    "    reader_test = create_reader(test_file, False, input_dim, num_output_classes)\n",
    "    train_test(reader_train, reader_test, z)\n",
    "    \n",
    "do_train_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, the average test error is very comparable to our training error indicating that our model has good \"out of sample\" error a.k.a. [generalization error](https://en.wikipedia.org/wiki/Generalization_error). This implies that our model can very effectively deal with previously unseen observations (during the training process). This is key to avoid [overfitting](https://en.wikipedia.org/wiki/Overfitting).\n",
    "\n",
    "Let us check what is the value of some of the network parameters. We will check the bias value of the output dense layer. Previously, it was all 0. Now you see there are non-zero values, indicating that a model parameters were updated during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias value of the last dense layer: [-0.00447022 -0.0033466  -0.00136732  0.00918391]\n"
     ]
    }
   ],
   "source": [
    "print(\"Bias value of the last dense layer:\", z.classify.b.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation / Prediction\n",
    "We have so far been dealing with aggregate measures of error. Let us now get the probabilities associated with individual data points. For each observation, the `eval` function returns the probability distribution across all the classes. The classifier is trained to recognize digits, hence has 10 classes. First let us route the network output through a `softmax` function. This maps the aggregated activations across the network to probabilities across the 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = C.softmax(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test a small minibatch sample from the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-c864efcf2f82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Read the data for evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcapstone_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"train_data.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mreader_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcapstone_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_output_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0meval_minibatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# Read the data for evaluation\n",
    "capstone_file=os.path.join(data_dir, \"train_data.txt\")\n",
    "reader_eval=create_reader(capstone_file, False, input_dim, num_output_classes)\n",
    "\n",
    "eval_minibatch_size = 25\n",
    "eval_input_map = {x: reader_eval.streams.features, y:reader_eval.streams.labels} \n",
    "\n",
    "data = reader_eval.next_minibatch(eval_minibatch_size, input_map=eval_input_map)\n",
    "\n",
    "img_label = data[y].asarray()\n",
    "img_data = data[x].asarray()\n",
    "\n",
    "# reshape img_data to: M x 1 x 28 x 28 to be compatible with model\n",
    "img_data = np.reshape(img_data, (eval_minibatch_size, 1, 64, 64))\n",
    "print(z.eval(img_data[img_data[0]]))\n",
    "\n",
    "predicted_label_prob = [out.eval(img_data[i]) for i in range(len(img_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0, 3, 2, 3, 2, 1, 0, 0, 0, 1, 3, 0, 2, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Find the index with the maximum value for both predicted as well as the ground truth\n",
    "pred = [np.argmax(predicted_label_prob[i]) for i in range(len(predicted_label_prob))]\n",
    "gtlabel = [np.argmax(img_label[i]) for i in range(len(img_label))]\n",
    "print(pred[0:15])\n",
    "print(gtlabel[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Capstone\\Test_results.csv', 'w') as result_file:\n",
    "        result_file.write('id,orientation\\n')  \n",
    "        for prediction in range(len(pred)):\n",
    "            result_file.write('{},{}\\n'.format(str(prediction+200000),str(pred[prediction])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualize some of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Label:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x225964f9a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a random image\n",
    "sample_number = 4\n",
    "plt.imshow(img_data[sample_number].reshape(64,64), cmap=\"gray_r\")\n",
    "plt.axis('off')\n",
    "\n",
    "img_gt, img_pred = gtlabel[sample_number], pred[sample_number]\n",
    "print(\"Image Label: \", img_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling Layer\n",
    "\n",
    "Often times, one needs to control the number of parameters especially when having deep networks. For every layer of the convolution layer output (each layer, corresponds to the output of a filter), one can have a pooling layer. Pooling layers are typically introduced to:\n",
    "- Reduce the shape of the current layer (speeding up the network),\n",
    "- Make the model more tolerant to changes in object location in the image. For example, even when a digit is shifted to one side of the image instead of being in the middle, the classifer would perform the classification task well.\n",
    "\n",
    "The calculation on a pooling node is much simpler than a normal feedforward node.  It has no weight, bias, or activation function.  It uses a simple aggregation function (like max or average) to compute its output.  The most commonly used function is \"max\" - a max pooling node simply outputs the maximum of the input values corresponding to the filter position of the input. The figure below shows the input values in a 4 x 4 region. The max pooling window size is 2 x 2 and starts from the top left corner, and uses a stride of 2x2.  The maximum value within the window becomes the output of the region. Every time the model is shifted by the amount specified by the stride parameter (as shown in the figure below) and the maximum pooling operation is repeated. \n",
    "![maxppool](https://cntk.ai/jup/201/MaxPooling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another alternative is average pooling, which emits that average value instead of the maximum value. The two different pooling opearations are summarized in the animation below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch: 0, Loss: 1.4093, Error: 77.34%\n",
      "Minibatch: 500, Loss: 0.4811, Error: 19.92%\n",
      "Minibatch: 1000, Loss: 0.2587, Error: 7.03%\n",
      "Minibatch: 1500, Loss: 0.2762, Error: 9.38%\n",
      "Minibatch: 2000, Loss: 0.3270, Error: 16.80%\n",
      "Minibatch: 2500, Loss: 0.2959, Error: 10.94%\n",
      "Minibatch: 3000, Loss: 0.1221, Error: 5.08%\n",
      "Minibatch: 3500, Loss: 0.1536, Error: 5.86%\n",
      "Minibatch: 4000, Loss: 0.1252, Error: 3.91%\n",
      "Minibatch: 4500, Loss: 0.1288, Error: 3.91%\n",
      "Minibatch: 5000, Loss: 0.0933, Error: 3.12%\n",
      "Minibatch: 5500, Loss: 0.1238, Error: 3.12%\n",
      "Minibatch: 6000, Loss: 0.0635, Error: 1.56%\n",
      "Minibatch: 6500, Loss: 0.1287, Error: 3.91%\n",
      "Minibatch: 7000, Loss: 0.0786, Error: 1.95%\n",
      "Minibatch: 7500, Loss: 0.1069, Error: 3.12%\n",
      "Minibatch: 8000, Loss: 0.1182, Error: 4.69%\n",
      "Minibatch: 8500, Loss: 0.1911, Error: 6.25%\n",
      "Minibatch: 9000, Loss: 0.1351, Error: 4.30%\n",
      "Minibatch: 9500, Loss: 0.0889, Error: 1.56%\n",
      "Minibatch: 10000, Loss: 0.0948, Error: 2.73%\n",
      "Minibatch: 10500, Loss: 0.0389, Error: 1.17%\n",
      "Minibatch: 11000, Loss: 0.1246, Error: 3.91%\n",
      "Minibatch: 11500, Loss: 0.0727, Error: 3.12%\n",
      "Minibatch: 12000, Loss: 0.1174, Error: 3.52%\n",
      "Minibatch: 12500, Loss: 0.1340, Error: 3.12%\n",
      "Minibatch: 13000, Loss: 0.0639, Error: 1.56%\n",
      "Minibatch: 13500, Loss: 0.0666, Error: 1.95%\n",
      "Minibatch: 14000, Loss: 0.1001, Error: 3.12%\n",
      "Minibatch: 14500, Loss: 0.0809, Error: 3.91%\n",
      "Minibatch: 15000, Loss: 0.0841, Error: 3.12%\n",
      "Minibatch: 15500, Loss: 0.0824, Error: 3.91%\n",
      "Minibatch: 16000, Loss: 0.0701, Error: 2.34%\n",
      "Minibatch: 16500, Loss: 0.0694, Error: 2.34%\n",
      "Minibatch: 17000, Loss: 0.1525, Error: 4.30%\n",
      "Minibatch: 17500, Loss: 0.0943, Error: 5.08%\n",
      "Minibatch: 18000, Loss: 0.0704, Error: 2.34%\n",
      "Minibatch: 18500, Loss: 0.1160, Error: 3.52%\n",
      "Training took 512.2 sec\n",
      "Average test error: 2.73%\n"
     ]
    }
   ],
   "source": [
    "# Modify this model\n",
    "def create_model(features):\n",
    "    with C.layers.default_options(init = C.glorot_uniform(), activation = C.relu):\n",
    "            h = features\n",
    "            \n",
    "            h = C.layers.Convolution2D(filter_shape=(3,3), \n",
    "                                       num_filters=8, \n",
    "                                       strides=(1,1), \n",
    "                                       pad=True, name='first_conv')(h)\n",
    "            #h = C.layers.AveragePooling(filter_shape=(3,3), \n",
    "            #                            strides=(2,2),\n",
    "            #                            name='first_pool')(h)        \n",
    "            h = C.layers.Convolution2D(filter_shape=(3,3), \n",
    "                                       num_filters=16, \n",
    "                                       strides=(1,1), \n",
    "                                       pad=True, name='second_conv')(h)\n",
    "            h = C.layers.AveragePooling(filter_shape=(3,3), \n",
    "                                        strides=(2,2),\n",
    "                                        name='second_pool')(h)        \n",
    "            r = C.layers.Dense(num_output_classes, activation = None, name='classify')(h)\n",
    "            return r\n",
    "        \n",
    "do_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 14244 parameters in 6 parameter tensors.\n"
     ]
    }
   ],
   "source": [
    "C.logging.log_number_of_parameters(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch: 0, Loss: 1.3911, Error: 78.52%\n",
      "Minibatch: 500, Loss: 0.6528, Error: 25.00%\n",
      "Minibatch: 1000, Loss: 0.1934, Error: 7.81%\n",
      "Minibatch: 1500, Loss: 0.1208, Error: 3.52%\n",
      "Minibatch: 2000, Loss: 0.1298, Error: 4.30%\n",
      "Minibatch: 2500, Loss: 0.0787, Error: 1.17%\n",
      "Minibatch: 3000, Loss: 0.0280, Error: 0.39%\n",
      "Minibatch: 3500, Loss: 0.0407, Error: 1.56%\n",
      "Minibatch: 4000, Loss: 0.0524, Error: 1.56%\n",
      "Minibatch: 4500, Loss: 0.0888, Error: 2.34%\n",
      "Minibatch: 5000, Loss: 0.0381, Error: 1.56%\n",
      "Minibatch: 5500, Loss: 0.0577, Error: 2.34%\n",
      "Minibatch: 6000, Loss: 0.0196, Error: 0.78%\n",
      "Minibatch: 6500, Loss: 0.0568, Error: 0.78%\n",
      "Minibatch: 7000, Loss: 0.0226, Error: 0.78%\n",
      "Minibatch: 7500, Loss: 0.0344, Error: 0.78%\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<built-in function MinibatchSource_get_next_minibatch> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\cntk\\cntk_py.py\u001b[0m in \u001b[0;36m__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2438\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2439\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_cntk_py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamInformation___hash__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in method 'StreamInformation___hash__', argument 1 of type 'CNTK::StreamInformation *'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-f706e61e04a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mdo_train_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-48-0055cec51ad8>\u001b[0m in \u001b[0;36mdo_train_test\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mreader_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_output_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mreader_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_output_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtrain_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreader_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdo_train_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-61-94c20c49b2be>\u001b[0m in \u001b[0;36mtrain_test\u001b[1;34m(train_reader, test_reader, model_func, num_sweeps_to_train_with)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_minibatches_to_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m# Read a mini batch from the training data file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_minibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminibatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_minibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mprint_training_progress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_progress_output_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\cntk\\internal\\swig_helper.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[0mmap_if_possible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\cntk\\io\\__init__.py\u001b[0m in \u001b[0;36mnext_minibatch\u001b[1;34m(self, minibatch_size_in_samples, input_map, device, num_data_partitions, partition_index)\u001b[0m\n\u001b[0;32m    290\u001b[0m                                             \u001b[0mminibatch_size_in_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m                                             \u001b[0mnum_data_partitions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m                                             partition_index, device)\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\cntk\\cntk_py.py\u001b[0m in \u001b[0;36mget_next_minibatch\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   2608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2609\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_minibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2610\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_cntk_py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMinibatchSource_get_next_minibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2611\u001b[0m \u001b[0mMinibatchSource_swigregister\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_cntk_py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMinibatchSource_swigregister\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2612\u001b[0m \u001b[0mMinibatchSource_swigregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMinibatchSource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: <built-in function MinibatchSource_get_next_minibatch> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "# Modify this model\n",
    "def create_model(features):\n",
    "    with C.layers.default_options(init = C.glorot_uniform(), activation = C.relu):\n",
    "            h = features\n",
    "            \n",
    "            h = C.layers.Convolution2D(filter_shape=(5,5), \n",
    "                                       num_filters=25, \n",
    "                                       strides=(2,2), \n",
    "                                       pad=True, name='first_conv')(h)\n",
    "            h = C.layers.Convolution2D(filter_shape=(5,5), \n",
    "                                       num_filters=50, \n",
    "                                       strides=(1,1), \n",
    "                                       pad=True, name='second_conv')(h)\n",
    "            h = C.layers.MaxPooling(filter_shape=(2,2),\n",
    "                                        name='first_pool')(h)        \n",
    "            h = C.layers.Convolution2D(filter_shape=(3,3), \n",
    "                                       num_filters=100, \n",
    "                                       strides=(2,2), \n",
    "                                       pad=True, name='third_conv')(h)\n",
    "            h = C.layers.MaxPooling(filter_shape=(2,2), \n",
    "                                       name='second_pool')(h)    \n",
    "            h = C.layers.Convolution2D(filter_shape=(3,3), \n",
    "                                       num_filters=200, \n",
    "                                       strides=(2,2), \n",
    "                                       pad=True, name='fourth_conv')(h)\n",
    "            h = C.layers.MaxPooling(filter_shape=(2,2), \n",
    "                                       name='second_pool')(h)\n",
    "            r = C.layers.Dense(num_output_classes, activation = None, name='classify')(h)\n",
    "            return r\n",
    "        \n",
    "do_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C.logging.graph.plot(model, 'model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolution_bn(input, filter_size, num_filters, strides=(1,1), init=C.he_normal(), activation=C.relu):\n",
    "    if activation is None:\n",
    "        activation = lambda x: x\n",
    "\n",
    "    r = C.layers.Convolution(filter_size,\n",
    "                             num_filters,\n",
    "                             strides=strides,\n",
    "                             init=init,\n",
    "                             activation=None,\n",
    "                             pad=True, bias=False)(input)\n",
    "    r = C.layers.BatchNormalization(map_rank=1)(r)\n",
    "    r = activation(r)\n",
    "\n",
    "    return r\n",
    "\n",
    "def resnet_basic(input, num_filters):\n",
    "    c1 = convolution_bn(input, (3,3), num_filters)\n",
    "    c2 = convolution_bn(c1, (3,3), num_filters, activation=None)\n",
    "    p  = c2 + input\n",
    "    return C.relu(p)\n",
    "\n",
    "def resnet_basic_inc(input, num_filters):\n",
    "    c1 = convolution_bn(input, (3,3), num_filters, strides=(2,2))\n",
    "    c2 = convolution_bn(c1, (3,3), num_filters, activation=None)\n",
    "\n",
    "    s = convolution_bn(input, (1,1), num_filters, strides=(2,2), activation=None)\n",
    "\n",
    "    p = c2 + s\n",
    "    return C.relu(p)\n",
    "\n",
    "def resnet_basic_stack(input, num_filters, num_stack):\n",
    "    assert (num_stack > 0)\n",
    "\n",
    "    r = input\n",
    "    for _ in range(num_stack):\n",
    "        r = resnet_basic(r, num_filters)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_resnet_model(input):\n",
    "    conv = convolution_bn(input, (3,3), 16)\n",
    "    r1_1 = resnet_basic_stack(conv, 16, 3)\n",
    "\n",
    "    r2_1 = resnet_basic_inc(r1_1, 32)\n",
    "    r2_2 = resnet_basic_stack(r2_1, 32, 2)\n",
    "\n",
    "    r3_1 = resnet_basic_inc(r2_2, 64)\n",
    "    r3_2 = resnet_basic_stack(r3_1, 64, 2)\n",
    "\n",
    "    # Global average pooling\n",
    "    pool = C.layers.AveragePooling(filter_shape=(8,8), strides=(1,1))(r3_2)\n",
    "    net = C.layers.Dense(num_output_classes, init=C.he_normal(), activation=None)(pool)\n",
    "\n",
    "    return net\n",
    "\n",
    "def do_train_test_ResNet():\n",
    "    global z\n",
    "    z = create_resnet_model(x)\n",
    "    reader_train = create_reader(train_file, True, input_dim, num_output_classes)\n",
    "    reader_test = create_reader(test_file, False, input_dim, num_output_classes)\n",
    "    train_test(reader_train, reader_test, z)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch: 0, Loss: 2.0070, Error: 76.56%\n",
      "Minibatch: 100, Loss: 0.3734, Error: 8.59%\n",
      "Minibatch: 200, Loss: 0.1959, Error: 3.91%\n",
      "Minibatch: 300, Loss: 0.1174, Error: 4.69%\n",
      "Minibatch: 400, Loss: 0.0752, Error: 1.56%\n",
      "Minibatch: 500, Loss: 0.1610, Error: 4.69%\n",
      "Minibatch: 600, Loss: 0.2099, Error: 1.56%\n",
      "Minibatch: 700, Loss: 0.0595, Error: 3.12%\n",
      "Minibatch: 800, Loss: 0.1320, Error: 2.34%\n",
      "Minibatch: 900, Loss: 0.0450, Error: 0.78%\n",
      "Minibatch: 1000, Loss: 0.0453, Error: 1.56%\n",
      "Minibatch: 1100, Loss: 0.0337, Error: 0.78%\n",
      "Minibatch: 1200, Loss: 0.0082, Error: 0.00%\n",
      "Minibatch: 1300, Loss: 0.0256, Error: 0.00%\n",
      "Minibatch: 1400, Loss: 0.0354, Error: 0.00%\n",
      "Minibatch: 1500, Loss: 0.0355, Error: 1.56%\n",
      "Minibatch: 1600, Loss: 0.0371, Error: 1.56%\n",
      "Minibatch: 1700, Loss: 0.0077, Error: 0.00%\n",
      "Minibatch: 1800, Loss: 0.0284, Error: 0.78%\n",
      "Minibatch: 1900, Loss: 0.0323, Error: 0.78%\n",
      "Minibatch: 2000, Loss: 0.0098, Error: 0.00%\n",
      "Minibatch: 2100, Loss: 0.0086, Error: 0.00%\n",
      "Minibatch: 2200, Loss: 0.0058, Error: 0.00%\n",
      "Minibatch: 2300, Loss: 0.0206, Error: 0.78%\n",
      "Minibatch: 2400, Loss: 0.0140, Error: 0.78%\n",
      "Minibatch: 2500, Loss: 0.0033, Error: 0.00%\n",
      "Minibatch: 2600, Loss: 0.0098, Error: 0.00%\n",
      "Minibatch: 2700, Loss: 0.0118, Error: 0.00%\n",
      "Minibatch: 2800, Loss: 0.0093, Error: 0.00%\n",
      "Minibatch: 2900, Loss: 0.0095, Error: 0.00%\n",
      "Minibatch: 3000, Loss: 0.0035, Error: 0.00%\n",
      "Minibatch: 3100, Loss: 0.0122, Error: 0.00%\n",
      "Training took 1089.2 sec\n",
      "Average test error: 0.53%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "do_train_test_ResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composite(Tensor[1,64,64]) -> Tensor[4]\n"
     ]
    }
   ],
   "source": [
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
