{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function # Use a function definition from future version (say 3.x from 2.7 interpreter)\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import cntk as C\n",
    "import cntk.tests.test_utils\n",
    "cntk.tests.test_utils.set_device_from_pytest_env() # (only needed for our build system)\n",
    "C.cntk_py.set_fixed_random_seed(1) # fix a random seed for CNTK components\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cognitive Toolkit is using the GPU for processing.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    isUsingGPU # if this is our first time running, this will cause an exception as undefined\n",
    "except NameError:\n",
    "    try:\n",
    "        isUsingGPU = C.device.try_set_default_device(C.device.gpu(0))\n",
    "    except ValueError:\n",
    "        isUsingGPU = False\n",
    "        C.device.try_set_default_device(C.device.cpu())\n",
    "\n",
    "print (\"The Cognitive Toolkit is using the {} for processing.\".format(\"GPU\" if isUsingGPU else \"CPU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the data dimensions\n",
    "input_dim_model = (1, 64, 64)    # images are 28 x 28 with 1 channel of color (gray)\n",
    "input_dim = 64*64                # used by readers to treat input data as a vector\n",
    "num_output_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Read a CTF formatted text (as mentioned above) using the CTF deserializer from a file\n",
    "def create_reader(path, is_training, input_dim, num_label_classes):\n",
    "\n",
    "    ctf = C.io.CTFDeserializer(path, C.io.StreamDefs(\n",
    "          labels=C.io.StreamDef(field='labels', shape=num_label_classes, is_sparse=False),\n",
    "          features=C.io.StreamDef(field='features', shape=input_dim, is_sparse=False)))\n",
    "\n",
    "    return C.io.MinibatchSource(ctf,\n",
    "        randomize = is_training, max_sweeps = C.io.INFINITELY_REPEAT if is_training else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory is Capstone\n"
     ]
    }
   ],
   "source": [
    "# Ensure the training and test data is available\n",
    "# We search in two locations in the toolkit for the cached MNIST data set.\n",
    "\n",
    "data_found=False # A flag to indicate if train/test data found in local cache\n",
    "for data_dir in [os.path.join(\"..\", \"Examples\", \"Image\", \"DataSets\", \"MNIST\"),\n",
    "                 os.path.join(\"Capstone\")]:\n",
    "    \n",
    "    train_file=os.path.join(data_dir, \"Train_data_all.txt\")\n",
    "    test_file=os.path.join(data_dir, \"Validation_data.txt\")\n",
    "    \n",
    "    if os.path.isfile(train_file) and os.path.isfile(test_file):\n",
    "        data_found=True\n",
    "        break\n",
    "        \n",
    "if not data_found:\n",
    "    raise ValueError(\"Please generate the data by completing Capstone_DataLoader\")\n",
    "    \n",
    "print(\"Data directory is {0}\".format(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = C.input_variable(input_dim_model)\n",
    "y = C.input_variable(num_output_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# function to build model\n",
    "def create_model(features):\n",
    "    with C.layers.default_options(init = C.glorot_uniform(), activation = C.relu):\n",
    "            h = features\n",
    "            \n",
    "            h = C.layers.Convolution2D(filter_shape=(3,3), \n",
    "                                       num_filters=50, \n",
    "                                       strides=(2,2), \n",
    "                                       pad=True, name='first_conv')(h)\n",
    "            h = C.layers.Convolution2D(filter_shape=(5,5), \n",
    "                                       num_filters=100, \n",
    "                                       strides=(1,1), \n",
    "                                       pad=True, name='second_conv')(h)\n",
    "            h = C.layers.MaxPooling(filter_shape=(2,2),\n",
    "                                        name='first_pool')(h)        \n",
    "            h = C.layers.Convolution2D(filter_shape=(3,3), \n",
    "                                       num_filters=200, \n",
    "                                       strides=(2,2), \n",
    "                                       pad=True, name='third_conv')(h)\n",
    "            h = C.layers.MaxPooling(filter_shape=(2,2), \n",
    "                                       name='second_pool')(h)    \n",
    "            h = C.layers.Convolution2D(filter_shape=(3,3), \n",
    "                                       num_filters=400, \n",
    "                                       strides=(2,2), \n",
    "                                       pad=True, name='fourth_conv')(h)\n",
    "            h = C.layers.MaxPooling(filter_shape=(2,2), \n",
    "                                       name='second_pool')(h)\n",
    "            h = C.layers.Convolution2D(filter_shape=(3,3), \n",
    "                                       num_filters=400, \n",
    "                                       strides=(2,2), \n",
    "                                       pad=True, name='fifth_conv')(h)\n",
    "            h = C.layers.MaxPooling(filter_shape=(2,2), \n",
    "                                       name='third_pool')(h)\n",
    "            h = C.layers.Convolution2D(filter_shape=(3,3), \n",
    "                                       num_filters=800, \n",
    "                                       strides=(2,2), \n",
    "                                       pad=True, name='sixth_conv')(h)\n",
    "            h = C.layers.MaxPooling(filter_shape=(2,2), \n",
    "                                       name='fourth_pool')(h)\n",
    "            r = C.layers.Dense(num_output_classes, activation = None, name='classify')(h)\n",
    "            return r\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Shape of the first convolution layer: (50, 32, 32)\n",
      "Bias value of the last dense layer: [0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "z = create_model(x)\n",
    "\n",
    "# Print the output shapes / parameters of different components\n",
    "print(\"Output Shape of the first convolution layer:\", z.first_conv.shape)\n",
    "print(\"Bias value of the last dense layer:\", z.classify.b.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 5350604 parameters in 14 parameter tensors.\n"
     ]
    }
   ],
   "source": [
    "# Number of parameters in the network\n",
    "C.logging.log_number_of_parameters(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_criterion_function(model, labels):\n",
    "    loss = C.cross_entropy_with_softmax(model, labels)\n",
    "    errs = C.classification_error(model, labels)\n",
    "    return loss, errs # (model, labels) -> (loss, error metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a utility function to compute the moving average sum.\n",
    "# A more efficient implementation is possible with np.cumsum() function\n",
    "def moving_average(a, w=5):\n",
    "    if len(a) < w:\n",
    "        return a[:]    # Need to send a copy of the array\n",
    "    return [val if idx < w else sum(a[(idx-w):idx])/w for idx, val in enumerate(a)]\n",
    "\n",
    "\n",
    "# Defines a utility that prints the training progress\n",
    "def print_training_progress(trainer, mb, frequency, verbose=1):\n",
    "    training_loss = \"NA\"\n",
    "    eval_error = \"NA\"\n",
    "\n",
    "    if mb%frequency == 0:\n",
    "        training_loss = trainer.previous_minibatch_loss_average\n",
    "        eval_error = trainer.previous_minibatch_evaluation_average\n",
    "        if verbose:\n",
    "            print (\"Minibatch: {0}, Loss: {1:.4f}, Error: {2:.2f}%\".format(mb, training_loss, eval_error*100))\n",
    "\n",
    "    return mb, training_loss, eval_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test(train_reader, test_reader, model_func, num_sweeps_to_train_with=50):\n",
    "\n",
    "    # Instantiate the model function; x is the input (feature) variable\n",
    "    # We will scale the input image pixels within 0-1 range by dividing all input value by 255.\n",
    "    model = model_func(x/255)\n",
    "\n",
    "    # Instantiate the loss and error function\n",
    "    loss, label_error = create_criterion_function(model, y)\n",
    "\n",
    "    # Instantiate the trainer object to drive the model training\n",
    "    learning_rate = 0.01\n",
    "    lr_schedule = C.learning_parameter_schedule(learning_rate)\n",
    "    learner = C.sgd(z.parameters, lr_schedule)\n",
    "    #learner = C.adagrad(z.parameters)\n",
    "    trainer = C.Trainer(z, (loss, label_error), [learner])\n",
    "\n",
    "    # Initialize the parameters for the trainer\n",
    "    minibatch_size = 64\n",
    "    num_samples_per_sweep = 60000\n",
    "    num_minibatches_to_train = (num_samples_per_sweep * num_sweeps_to_train_with) / minibatch_size\n",
    "\n",
    "    # Map the data streams to the input and labels.\n",
    "    input_map={\n",
    "        y  : train_reader.streams.labels,\n",
    "        x  : train_reader.streams.features\n",
    "    }\n",
    "\n",
    "    # Uncomment below for more detailed logging\n",
    "    training_progress_output_freq = 500\n",
    "\n",
    "    # Start a timer\n",
    "    start = time.time()\n",
    "\n",
    "    for i in range(0, int(num_minibatches_to_train)):\n",
    "        # Read a mini batch from the training data file\n",
    "        data=train_reader.next_minibatch(minibatch_size, input_map=input_map)\n",
    "        trainer.train_minibatch(data)\n",
    "        print_training_progress(trainer, i, training_progress_output_freq, verbose=1)\n",
    "\n",
    "    # Print training time\n",
    "    print(\"Training took {:.1f} sec\".format(time.time() - start))\n",
    "\n",
    "    # Test the model\n",
    "    test_input_map = {\n",
    "        y  : test_reader.streams.labels,\n",
    "        x  : test_reader.streams.features\n",
    "    }\n",
    "\n",
    "    # Test data for trained model\n",
    "    test_minibatch_size = 512\n",
    "    num_samples = 20000\n",
    "    num_minibatches_to_test = num_samples // test_minibatch_size\n",
    "\n",
    "    test_result = 0.0\n",
    "\n",
    "    for i in range(num_minibatches_to_test):\n",
    "\n",
    "        # We are loading test data in batches specified by test_minibatch_size\n",
    "        # Each data point in the minibatch is a MNIST digit image of 784 dimensions\n",
    "        # with one pixel per dimension that we will encode / decode with the\n",
    "        # trained model.\n",
    "        data = test_reader.next_minibatch(test_minibatch_size, input_map=test_input_map)\n",
    "        eval_error = trainer.test_minibatch(data)\n",
    "        test_result = test_result + eval_error\n",
    "\n",
    "    # Average of evaluation errors of all test minibatches\n",
    "    print(\"Average test error: {0:.2f}%\".format(test_result*100 / num_minibatches_to_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch: 0, Loss: 1.3866, Error: 73.44%\n",
      "Minibatch: 500, Loss: 1.3155, Error: 12.50%\n",
      "Minibatch: 1000, Loss: 0.3647, Error: 18.75%\n",
      "Minibatch: 1500, Loss: 0.3031, Error: 15.62%\n",
      "Minibatch: 2000, Loss: 0.1358, Error: 4.69%\n",
      "Minibatch: 2500, Loss: 0.0555, Error: 1.56%\n",
      "Minibatch: 3000, Loss: 0.0592, Error: 4.69%\n",
      "Minibatch: 3500, Loss: 0.0819, Error: 1.56%\n",
      "Minibatch: 4000, Loss: 0.0759, Error: 4.69%\n",
      "Minibatch: 4500, Loss: 0.0500, Error: 0.00%\n",
      "Minibatch: 5000, Loss: 0.0058, Error: 0.00%\n",
      "Minibatch: 5500, Loss: 0.0074, Error: 0.00%\n",
      "Minibatch: 6000, Loss: 0.0020, Error: 0.00%\n",
      "Minibatch: 6500, Loss: 0.0120, Error: 0.00%\n",
      "Minibatch: 7000, Loss: 0.0028, Error: 0.00%\n",
      "Minibatch: 7500, Loss: 0.0199, Error: 1.56%\n",
      "Minibatch: 8000, Loss: 0.0741, Error: 3.12%\n",
      "Minibatch: 8500, Loss: 0.0743, Error: 3.12%\n",
      "Minibatch: 9000, Loss: 0.0050, Error: 0.00%\n",
      "Minibatch: 9500, Loss: 0.0102, Error: 0.00%\n",
      "Minibatch: 10000, Loss: 0.0016, Error: 0.00%\n",
      "Minibatch: 10500, Loss: 0.0060, Error: 0.00%\n",
      "Minibatch: 11000, Loss: 0.0103, Error: 0.00%\n",
      "Minibatch: 11500, Loss: 0.0096, Error: 0.00%\n",
      "Minibatch: 12000, Loss: 0.0020, Error: 0.00%\n",
      "Minibatch: 12500, Loss: 0.0201, Error: 1.56%\n",
      "Minibatch: 13000, Loss: 0.0135, Error: 0.00%\n",
      "Minibatch: 13500, Loss: 0.0033, Error: 0.00%\n",
      "Minibatch: 14000, Loss: 0.0065, Error: 0.00%\n",
      "Minibatch: 14500, Loss: 0.0014, Error: 0.00%\n",
      "Minibatch: 15000, Loss: 0.0044, Error: 0.00%\n",
      "Minibatch: 15500, Loss: 0.0410, Error: 3.12%\n",
      "Minibatch: 16000, Loss: 0.0009, Error: 0.00%\n",
      "Minibatch: 16500, Loss: 0.0014, Error: 0.00%\n",
      "Minibatch: 17000, Loss: 0.0002, Error: 0.00%\n",
      "Minibatch: 17500, Loss: 0.0006, Error: 0.00%\n",
      "Minibatch: 18000, Loss: 0.0003, Error: 0.00%\n",
      "Minibatch: 18500, Loss: 0.0012, Error: 0.00%\n",
      "Minibatch: 19000, Loss: 0.0013, Error: 0.00%\n",
      "Minibatch: 19500, Loss: 0.0030, Error: 0.00%\n",
      "Minibatch: 20000, Loss: 0.0015, Error: 0.00%\n",
      "Minibatch: 20500, Loss: 0.0009, Error: 0.00%\n",
      "Minibatch: 21000, Loss: 0.0009, Error: 0.00%\n",
      "Minibatch: 21500, Loss: 0.0001, Error: 0.00%\n",
      "Minibatch: 22000, Loss: 0.0324, Error: 1.56%\n",
      "Minibatch: 22500, Loss: 0.0007, Error: 0.00%\n",
      "Minibatch: 23000, Loss: 0.0011, Error: 0.00%\n",
      "Minibatch: 23500, Loss: 0.0012, Error: 0.00%\n",
      "Minibatch: 24000, Loss: 0.0000, Error: 0.00%\n",
      "Minibatch: 24500, Loss: 0.0008, Error: 0.00%\n",
      "Minibatch: 25000, Loss: 0.0001, Error: 0.00%\n",
      "Minibatch: 25500, Loss: 0.0000, Error: 0.00%\n",
      "Minibatch: 26000, Loss: 0.0001, Error: 0.00%\n",
      "Minibatch: 26500, Loss: 0.0002, Error: 0.00%\n",
      "Minibatch: 27000, Loss: 0.0010, Error: 0.00%\n",
      "Minibatch: 27500, Loss: 0.0003, Error: 0.00%\n",
      "Minibatch: 28000, Loss: 0.0003, Error: 0.00%\n",
      "Minibatch: 28500, Loss: 0.0000, Error: 0.00%\n",
      "Minibatch: 29000, Loss: 0.0000, Error: 0.00%\n",
      "Minibatch: 29500, Loss: 0.0004, Error: 0.00%\n",
      "Minibatch: 30000, Loss: 0.0005, Error: 0.00%\n",
      "Minibatch: 30500, Loss: 0.0001, Error: 0.00%\n",
      "Minibatch: 31000, Loss: 0.0001, Error: 0.00%\n",
      "Minibatch: 31500, Loss: 0.0001, Error: 0.00%\n",
      "Minibatch: 32000, Loss: 0.0000, Error: 0.00%\n",
      "Minibatch: 32500, Loss: 0.0002, Error: 0.00%\n",
      "Minibatch: 33000, Loss: 0.0001, Error: 0.00%\n",
      "Minibatch: 33500, Loss: 0.0001, Error: 0.00%\n",
      "Minibatch: 34000, Loss: 0.0001, Error: 0.00%\n",
      "Minibatch: 34500, Loss: 0.0286, Error: 1.56%\n",
      "Minibatch: 35000, Loss: 0.0005, Error: 0.00%\n",
      "Minibatch: 35500, Loss: 0.0000, Error: 0.00%\n",
      "Minibatch: 36000, Loss: 0.0159, Error: 1.56%\n",
      "Minibatch: 36500, Loss: 0.0002, Error: 0.00%\n",
      "Minibatch: 37000, Loss: 0.0001, Error: 0.00%\n",
      "Minibatch: 37500, Loss: 0.0000, Error: 0.00%\n",
      "Minibatch: 38000, Loss: 0.0003, Error: 0.00%\n",
      "Minibatch: 38500, Loss: 0.0005, Error: 0.00%\n",
      "Minibatch: 39000, Loss: 0.0000, Error: 0.00%\n",
      "Minibatch: 39500, Loss: 0.0000, Error: 0.00%\n",
      "Minibatch: 40000, Loss: 0.0000, Error: 0.00%\n",
      "Minibatch: 40500, Loss: 0.0125, Error: 0.00%\n",
      "Minibatch: 41000, Loss: 0.0023, Error: 0.00%\n",
      "Minibatch: 41500, Loss: 0.0012, Error: 0.00%\n",
      "Minibatch: 42000, Loss: 0.0007, Error: 0.00%\n",
      "Minibatch: 42500, Loss: 0.0002, Error: 0.00%\n",
      "Minibatch: 43000, Loss: 0.0001, Error: 0.00%\n",
      "Minibatch: 43500, Loss: 0.0003, Error: 0.00%\n",
      "Minibatch: 44000, Loss: 0.0005, Error: 0.00%\n",
      "Minibatch: 44500, Loss: 0.0182, Error: 1.56%\n",
      "Minibatch: 45000, Loss: 0.0013, Error: 0.00%\n",
      "Minibatch: 45500, Loss: 0.0006, Error: 0.00%\n",
      "Minibatch: 46000, Loss: 0.0009, Error: 0.00%\n",
      "Minibatch: 46500, Loss: 0.0007, Error: 0.00%\n",
      "Training took 4611.2 sec\n",
      "Average test error: 0.11%\n"
     ]
    }
   ],
   "source": [
    "def do_train_test():\n",
    "    global z\n",
    "    z = create_model(x)\n",
    "    reader_train = create_reader(train_file, True, input_dim, num_output_classes)\n",
    "    reader_test = create_reader(test_file, False, input_dim, num_output_classes)\n",
    "    train_test(reader_train, reader_test, z)\n",
    "\n",
    "do_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias value of the last dense layer: [ 0.00576137 -0.01523683  0.00789823  0.00156526]\n"
     ]
    }
   ],
   "source": [
    "print(\"Bias value of the last dense layer:\", z.classify.b.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = C.softmax(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the data for evaluation\n",
    "reader_eval=create_reader(test_file, False, input_dim, num_output_classes)\n",
    "\n",
    "eval_minibatch_size = 25\n",
    "eval_input_map = {x: reader_eval.streams.features, y:reader_eval.streams.labels}\n",
    "\n",
    "data = reader_eval.next_minibatch(eval_minibatch_size, input_map=eval_input_map)\n",
    "\n",
    "img_label = data[y].asarray()\n",
    "img_data = data[x].asarray()\n",
    "\n",
    "# reshape img_data to: M x 1 x 28 x 28 to be compatible with model\n",
    "img_data = np.reshape(img_data, (eval_minibatch_size, 1, 64, 64))\n",
    "\n",
    "predicted_label_prob = [out.eval(img_data[i]) for i in range(len(img_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Find the index with the maximum value for both predicted as well as the ground truth\n",
    "pred = [np.argmax(predicted_label_prob[i]) for i in range(len(predicted_label_prob))]\n",
    "gtlabel = [np.argmax(img_label[i]) for i in range(len(img_label))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label    : [3, 2, 1, 2, 1, 0, 3, 3, 3, 0, 2, 3, 1, 3, 0, 1, 2, 1, 2, 2, 1, 0, 1, 0, 2]\n",
      "Predicted: [3, 2, 1, 2, 1, 0, 3, 3, 3, 0, 2, 3, 1, 3, 0, 1, 2, 1, 2, 2, 1, 0, 1, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Label    :\", gtlabel[:25])\n",
    "print(\"Predicted:\", pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Label:  1\n",
      "Predicted Label:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQlSIFF+ICpHiC1Eh/wfeB9kKAjMg9QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2301a81f710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a random image\n",
    "sample_number = 12\n",
    "plt.imshow(img_data[sample_number].reshape(64,64), cmap=\"gray_r\")\n",
    "plt.axis('off')\n",
    "\n",
    "img_gt, img_pred = gtlabel[sample_number], pred[sample_number]\n",
    "print(\"Image Label: \", img_gt)\n",
    "print(\"Predicted Label: \", img_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the capstone data for evaluation\n",
    "capstone_file=os.path.join(data_dir, \"test_data.txt\")\n",
    "reader_eval=create_reader(capstone_file, False, input_dim, num_output_classes)\n",
    "\n",
    "eval_minibatch_size = 20000\n",
    "eval_input_map = {x: reader_eval.streams.features, y:reader_eval.streams.labels}\n",
    "\n",
    "data = reader_eval.next_minibatch(eval_minibatch_size, input_map=eval_input_map)\n",
    "\n",
    "img_label = data[y].asarray()\n",
    "img_data = data[x].asarray()\n",
    "\n",
    "# reshape img_data to: M x 1 x 28 x 28 to be compatible with model\n",
    "img_data = np.reshape(img_data, (eval_minibatch_size, 1, 64, 64))\n",
    "\n",
    "predicted_label_prob = [out.eval(img_data[i]) for i in range(len(img_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Find the index with the maximum value for both predicted as well as the ground truth\n",
    "pred = [np.argmax(predicted_label_prob[i]) for i in range(len(predicted_label_prob))]\n",
    "gtlabel = [np.argmax(img_label[i]) for i in range(len(img_label))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label    : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Predicted: [3, 3, 3, 2, 3, 1, 1, 0, 1, 0, 2, 0, 1, 0, 1, 1, 1, 3, 3, 3, 0, 2, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Label    :\", gtlabel[:25])\n",
    "print(\"Predicted:\", pred[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Capstone\\Test_results.csv', 'w') as result_file:\n",
    "        result_file.write('id,orientation\\n')  \n",
    "        for prediction in range(len(pred)):\n",
    "            result_file.write('{},{}\\n'.format(str(prediction+200000),str(pred[prediction])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
