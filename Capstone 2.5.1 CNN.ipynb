{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function # Use a function definition from future version (say 3.x from 2.7 interpreter)\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import cntk as C\n",
    "import cntk.tests.test_utils\n",
    "cntk.tests.test_utils.set_device_from_pytest_env() # (only needed for our build system)\n",
    "C.cntk_py.set_fixed_random_seed(1) # fix a random seed for CNTK components\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the data dimensions\n",
    "input_dim_model = (1, 64, 64)    # images are 28 x 28 with 1 channel of color (gray)\n",
    "input_dim = 64*64                # used by readers to treat input data as a vector\n",
    "num_output_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Read a CTF formatted text (as mentioned above) using the CTF deserializer from a file\n",
    "def create_reader(path, is_training, input_dim, num_label_classes):\n",
    "\n",
    "    ctf = C.io.CTFDeserializer(path, C.io.StreamDefs(\n",
    "          labels=C.io.StreamDef(field='labels', shape=num_label_classes, is_sparse=False),\n",
    "          features=C.io.StreamDef(field='features', shape=input_dim, is_sparse=False)))\n",
    "\n",
    "    return C.io.MinibatchSource(ctf,\n",
    "        randomize = is_training, max_sweeps = C.io.INFINITELY_REPEAT if is_training else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory is Capstone\n"
     ]
    }
   ],
   "source": [
    "# Ensure the training and test data is available\n",
    "# We search in two locations in the toolkit for the cached MNIST data set.\n",
    "\n",
    "data_found=False # A flag to indicate if train/test data found in local cache\n",
    "for data_dir in [os.path.join(\"..\", \"Examples\", \"Image\", \"DataSets\", \"MNIST\"),\n",
    "                 os.path.join(\"Capstone\")]:\n",
    "    \n",
    "    train_file=os.path.join(data_dir, \"Train_data.txt\")\n",
    "    test_file=os.path.join(data_dir, \"Validation_data.txt\")\n",
    "    \n",
    "    if os.path.isfile(train_file) and os.path.isfile(test_file):\n",
    "        data_found=True\n",
    "        break\n",
    "        \n",
    "if not data_found:\n",
    "    raise ValueError(\"Please generate the data by completing Capstone_DataLoader\")\n",
    "    \n",
    "print(\"Data directory is {0}\".format(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = C.input_variable(input_dim_model)\n",
    "y = C.input_variable(num_output_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# function to build model\n",
    "\n",
    "def create_model(features):\n",
    "    with C.layers.default_options(init=C.glorot_uniform(), activation=C.relu):\n",
    "            h = features\n",
    "            h = C.layers.Convolution2D(filter_shape=(5,5),\n",
    "                                       num_filters=8,\n",
    "                                       strides=(2,2),\n",
    "                                       pad=True, name='first_conv')(h)\n",
    "            h = C.layers.Convolution2D(filter_shape=(5,5),\n",
    "                                       num_filters=16,\n",
    "                                       strides=(2,2),\n",
    "                                       pad=True, name='second_conv')(h)\n",
    "            r = C.layers.Dense(num_output_classes, activation=None, name='classify')(h)\n",
    "            return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Shape of the first convolution layer: (8, 32, 32)\n",
      "Bias value of the last dense layer: [0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "z = create_model(x)\n",
    "\n",
    "# Print the output shapes / parameters of different components\n",
    "print(\"Output Shape of the first convolution layer:\", z.first_conv.shape)\n",
    "print(\"Bias value of the last dense layer:\", z.classify.b.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 19812 parameters in 6 parameter tensors.\n"
     ]
    }
   ],
   "source": [
    "# Number of parameters in the network\n",
    "C.logging.log_number_of_parameters(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_criterion_function(model, labels):\n",
    "    loss = C.cross_entropy_with_softmax(model, labels)\n",
    "    errs = C.classification_error(model, labels)\n",
    "    return loss, errs # (model, labels) -> (loss, error metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a utility function to compute the moving average sum.\n",
    "# A more efficient implementation is possible with np.cumsum() function\n",
    "def moving_average(a, w=5):\n",
    "    if len(a) < w:\n",
    "        return a[:]    # Need to send a copy of the array\n",
    "    return [val if idx < w else sum(a[(idx-w):idx])/w for idx, val in enumerate(a)]\n",
    "\n",
    "\n",
    "# Defines a utility that prints the training progress\n",
    "def print_training_progress(trainer, mb, frequency, verbose=1):\n",
    "    training_loss = \"NA\"\n",
    "    eval_error = \"NA\"\n",
    "\n",
    "    if mb%frequency == 0:\n",
    "        training_loss = trainer.previous_minibatch_loss_average\n",
    "        eval_error = trainer.previous_minibatch_evaluation_average\n",
    "        if verbose:\n",
    "            print (\"Minibatch: {0}, Loss: {1:.4f}, Error: {2:.2f}%\".format(mb, training_loss, eval_error*100))\n",
    "\n",
    "    return mb, training_loss, eval_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test(train_reader, test_reader, model_func, num_sweeps_to_train_with=10):\n",
    "\n",
    "    # Instantiate the model function; x is the input (feature) variable\n",
    "    # We will scale the input image pixels within 0-1 range by dividing all input value by 255.\n",
    "    model = model_func(x/255)\n",
    "\n",
    "    # Instantiate the loss and error function\n",
    "    loss, label_error = create_criterion_function(model, y)\n",
    "\n",
    "    # Instantiate the trainer object to drive the model training\n",
    "    learning_rate = 0.01\n",
    "    lr_schedule = C.learning_parameter_schedule(learning_rate)\n",
    "    learner = C.sgd(z.parameters, lr_schedule)\n",
    "    trainer = C.Trainer(z, (loss, label_error), [learner])\n",
    "\n",
    "    # Initialize the parameters for the trainer\n",
    "    minibatch_size = 64\n",
    "    num_samples_per_sweep = 20000\n",
    "    num_minibatches_to_train = (num_samples_per_sweep * num_sweeps_to_train_with) / minibatch_size\n",
    "\n",
    "    # Map the data streams to the input and labels.\n",
    "    input_map={\n",
    "        y  : train_reader.streams.labels,\n",
    "        x  : train_reader.streams.features\n",
    "    }\n",
    "\n",
    "    # Uncomment below for more detailed logging\n",
    "    training_progress_output_freq = 500\n",
    "\n",
    "    # Start a timer\n",
    "    start = time.time()\n",
    "\n",
    "    for i in range(0, int(num_minibatches_to_train)):\n",
    "        # Read a mini batch from the training data file\n",
    "        data=train_reader.next_minibatch(minibatch_size, input_map=input_map)\n",
    "        trainer.train_minibatch(data)\n",
    "        print_training_progress(trainer, i, training_progress_output_freq, verbose=1)\n",
    "\n",
    "    # Print training time\n",
    "    print(\"Training took {:.1f} sec\".format(time.time() - start))\n",
    "\n",
    "    # Test the model\n",
    "    test_input_map = {\n",
    "        y  : test_reader.streams.labels,\n",
    "        x  : test_reader.streams.features\n",
    "    }\n",
    "\n",
    "    # Test data for trained model\n",
    "    test_minibatch_size = 512\n",
    "    num_samples = 20000\n",
    "    num_minibatches_to_test = num_samples // test_minibatch_size\n",
    "\n",
    "    test_result = 0.0\n",
    "\n",
    "    for i in range(num_minibatches_to_test):\n",
    "\n",
    "        # We are loading test data in batches specified by test_minibatch_size\n",
    "        # Each data point in the minibatch is a MNIST digit image of 784 dimensions\n",
    "        # with one pixel per dimension that we will encode / decode with the\n",
    "        # trained model.\n",
    "        data = test_reader.next_minibatch(test_minibatch_size, input_map=test_input_map)\n",
    "        eval_error = trainer.test_minibatch(data)\n",
    "        test_result = test_result + eval_error\n",
    "\n",
    "    # Average of evaluation errors of all test minibatches\n",
    "    print(\"Average test error: {0:.2f}%\".format(test_result*100 / num_minibatches_to_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch: 0, Loss: 1.3794, Error: 68.75%\n",
      "Minibatch: 500, Loss: 0.2763, Error: 9.38%\n",
      "Minibatch: 1000, Loss: 0.2734, Error: 6.25%\n",
      "Minibatch: 1500, Loss: 0.1574, Error: 9.38%\n",
      "Minibatch: 2000, Loss: 0.1519, Error: 3.12%\n",
      "Minibatch: 2500, Loss: 0.0516, Error: 0.00%\n",
      "Minibatch: 3000, Loss: 0.1376, Error: 3.12%\n",
      "Training took 15.3 sec\n",
      "Average test error: 2.17%\n"
     ]
    }
   ],
   "source": [
    "def do_train_test():\n",
    "    global z\n",
    "    z = create_model(x)\n",
    "    reader_train = create_reader(train_file, True, input_dim, num_output_classes)\n",
    "    reader_test = create_reader(test_file, False, input_dim, num_output_classes)\n",
    "    train_test(reader_train, reader_test, z)\n",
    "\n",
    "do_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias value of the last dense layer: [-2.4177094e-03  1.3512335e-03  9.7737752e-04  8.9119123e-05]\n"
     ]
    }
   ],
   "source": [
    "print(\"Bias value of the last dense layer:\", z.classify.b.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = C.softmax(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the data for evaluation\n",
    "reader_eval=create_reader(test_file, False, input_dim, num_output_classes)\n",
    "\n",
    "eval_minibatch_size = 25\n",
    "eval_input_map = {x: reader_eval.streams.features, y:reader_eval.streams.labels}\n",
    "\n",
    "data = reader_eval.next_minibatch(eval_minibatch_size, input_map=eval_input_map)\n",
    "\n",
    "img_label = data[y].asarray()\n",
    "img_data = data[x].asarray()\n",
    "\n",
    "# reshape img_data to: M x 1 x 28 x 28 to be compatible with model\n",
    "img_data = np.reshape(img_data, (eval_minibatch_size, 1, 64, 64))\n",
    "\n",
    "predicted_label_prob = [out.eval(img_data[i]) for i in range(len(img_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Find the index with the maximum value for both predicted as well as the ground truth\n",
    "pred = [np.argmax(predicted_label_prob[i]) for i in range(len(predicted_label_prob))]\n",
    "gtlabel = [np.argmax(img_label[i]) for i in range(len(img_label))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label    : [3, 2, 1, 2, 1, 0, 3, 3, 3, 0, 2, 3, 1, 3, 0, 1, 2, 1, 2, 2, 1, 0, 1, 0, 2]\n",
      "Predicted: [3, 0, 1, 2, 1, 0, 3, 3, 3, 0, 2, 3, 1, 3, 2, 1, 2, 1, 2, 2, 1, 0, 1, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Label    :\", gtlabel[:25])\n",
    "print(\"Predicted:\", pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Label:  2\n",
      "Predicted Label:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzP8kewAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20a27950160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a random image\n",
    "sample_number = 1\n",
    "plt.imshow(img_data[sample_number].reshape(64,64), cmap=\"gray_r\")\n",
    "plt.axis('off')\n",
    "\n",
    "img_gt, img_pred = gtlabel[sample_number], pred[sample_number]\n",
    "print(\"Image Label: \", img_gt)\n",
    "print(\"Predicted Label: \", img_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cntk.device' has no attribute 'default'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8202c7e7fdca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcntk\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'running on CPU'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'running on GPU'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cntk.device' has no attribute 'default'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
